{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First steps in PySpark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with RDD and Pair RDD abstractions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def plural(string): \n",
    "    return string + 's'\n",
    "\n",
    "hats = [ random.choice(['panama', 'sombrero', 'fedora', 'top hat']) for _ in range(100) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:480"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_rdd = sc.parallelize(hats) \n",
    "my_first_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals = my_first_rdd.map(plural) \n",
    "hat_plurals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['panamas', 'panamas', 'fedoras', 'sombreros', 'sombreros']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.take(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Calculate, from the rdd generated from hats, how many hats we have whose name does **not** start with an 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals\\\n",
    "    .filter(lambda x: x[0] != 's')\\\n",
    "    .count()\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Levels can save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import StorageLevel\n",
    "\n",
    "# Some of the possible storage levels\n",
    "StorageLevel.DISK_ONLY\n",
    "StorageLevel.MEMORY_AND_DISK_2\n",
    "StorageLevel.MEMORY_ONLY_SER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.cache() # equivalent to: hat_plurals.persist(StorageLevel.MEMORY_ONLY_SER) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.map(lambda x: 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.unpersist()\n",
    "hat_plurals.persist(StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, False, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "repartitioned = sc.parallelize(range(20)).repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartitioned.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 16, 17, 18, 19],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [],\n",
       " [],\n",
       " [10, 11, 12, 13, 14]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartitioned.glom().collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping strategies in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['panama', 'panama', 'fedora', 'sombrero', 'sombrero']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('panama', 1), ('panama', 1), ('fedora', 1), ('sombrero', 1), ('sombrero', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd = my_first_rdd.map(lambda word: (word, 1))\n",
    "pair_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fedora', 24), ('top hat', 20), ('panama', 27), ('sombrero', 29)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd.groupByKey().mapValues(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fedora', 24), ('top hat', 20), ('panama', 27), ('sombrero', 29)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fedora', 24), ('top hat', 20), ('panama', 27)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing all steps at once\n",
    "my_first_rdd\\\n",
    "    .filter(lambda hat: hat[0] != 's')\\\n",
    "    .map(lambda hat: (hat, 1))\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apply word count to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [Complete Works of William Shakespeare](http://www.gutenberg.org/ebooks/100) from [Project Gutenberg](http://www.gutenberg.org/wiki/Main_Page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-08 12:38:33--  http://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5852404 (5,6M) [text/plain]\n",
      "Saving to: ‘shakespeare.txt’\n",
      "\n",
      "shakespeare.txt     100%[===================>]   5,58M  1,61MB/s    in 4,0s    \n",
      "\n",
      "2018-09-08 12:38:38 (1,41 MB/s) - ‘shakespeare.txt’ saved [5852404/5852404]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -v http://www.gutenberg.org/files/100/100-0.txt -O shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\r",
      "\r\n",
      "Project Gutenberg’s The Complete Works of William Shakespeare, by William\r",
      "\r\n",
      "Shakespeare\r",
      "\r\n",
      "\r",
      "\r\n",
      "This eBook is for the use of anyone anywhere in the United States and\r",
      "\r\n",
      "most other parts of the world at no cost and with almost no restrictions\r",
      "\r\n",
      "whatsoever.  You may copy it, give it away or re-use it under the terms\r",
      "\r\n",
      "of the Project Gutenberg License included with this eBook or online at\r",
      "\r\n",
      "www.gutenberg.org.  If you are not located in the United States, you’ll\r",
      "\r\n",
      "have to check the laws of the country where you are located before using\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head shakespeare.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing capitalization and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'see at the end of this file  content note added in 2017 '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test_line = 'See at the end of this file: * CONTENT NOTE (added in 2017) *'\n",
    "\n",
    "def clean(line):\n",
    "    return re.sub('[^\\w ]', '', line).lower()\n",
    "    \n",
    "clean(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'project gutenbergs the complete works of william shakespeare by william',\n",
       " 'shakespeare',\n",
       " '',\n",
       " 'this ebook is for the use of anyone anywhere in the united states and',\n",
       " 'most other parts of the world at no cost and with almost no restrictions',\n",
       " 'whatsoever  you may copy it give it away or reuse it under the terms',\n",
       " 'of the project gutenberg license included with this ebook or online at',\n",
       " 'wwwgutenbergorg  if you are not located in the united states youll',\n",
       " 'have to check the laws of the country where you are located before using']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lines = sc.textFile('shakespeare.txt')\n",
    "clean_lines = clean_lines.map(clean)\n",
    "clean_lines.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenbergs',\n",
       " 'the',\n",
       " 'complete',\n",
       " 'works',\n",
       " 'of',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'by',\n",
       " 'william']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = clean_lines.flatMap(lambda line: line.split()) \n",
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words.filter(lambda word: word != '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2d.5) Count the words and show the top 15\n",
    "\n",
    "We know the drill at this point, don't we? We map to a tuple then `reduceByKey`\n",
    "\n",
    "We can view the top 15 words by using the `takeOrdered()` action; however, since the elements of the RDD are pair tuples, we need a custom sort function that sorts using the value part of the pair rather than the key.\n",
    "\n",
    "You'll notice that many of the words are common English words (know as stopwords).\n",
    "\n",
    "Use our map reduce and and `takeOrdered()` to obtain the fifteen most common words and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "\n",
    "counts = words\\\n",
    "    .map(lambda word: (word, 1))\\\n",
    "    .reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 30002),\n",
       " ('and', 28358),\n",
       " ('i', 21867),\n",
       " ('to', 20816),\n",
       " ('of', 18815),\n",
       " ('a', 15992),\n",
       " ('you', 14437),\n",
       " ('my', 13191),\n",
       " ('in', 12032),\n",
       " ('that', 11781)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.takeOrdered(10, lambda tup: -tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical - ETL with airline coupon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['79062005698500,1,MAA,AUH,9W,9W,56.79,USD,1,H,H,0526,150904,OK,IAF0',\n",
       " '79062005698500,2,AUH,CDG,9W,9W,84.34,USD,1,H,H,6120,150905,OK,IAF0',\n",
       " '79062005924069,1,CJB,MAA,9W,9W,60.0,USD,1,H,H,2768,150721,OK,IAA0',\n",
       " '79065668570385,1,DEL,DXB,9W,9W,160.63,USD,2,S,S,0546,150804,OK,INA0',\n",
       " '79065668737021,1,AUH,IXE,9W,9W,152.46,USD,1,V,V,0501,150803,OK,INA0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile('coupon150720.csv')\n",
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Take fields 0, 2, 3, 4, and 6 from each line of coupons\n",
    "2. Keep only the amount. Get average, max, min and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('79062005698500', 'MAA', 'AUH', '9W', 56.79)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_line = '79062005698500,1,MAA,AUH,9W,9W,56.79,USD,1,H,H,0526,150904,OK,IAF0'\n",
    "\n",
    "def coupon_from_line(line):\n",
    "    fields = line.split(',')\n",
    "    return fields[0], fields[2], fields[3], fields[4], float(fields[6])\n",
    "\n",
    "coupon_from_line(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79062005698500', 'MAA', 'AUH', '9W', 56.79),\n",
       " ('79062005698500', 'AUH', 'CDG', '9W', 84.34),\n",
       " ('79062005924069', 'CJB', 'MAA', '9W', 60.0),\n",
       " ('79065668570385', 'DEL', 'DXB', '9W', 160.63),\n",
       " ('79065668737021', 'AUH', 'IXE', '9W', 152.46)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupons = lines.map(coupon_from_line)\n",
    "coupons.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56.79, 84.34, 60.0, 160.63]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amounts = coupons.map(lambda coupon: coupon[4])\n",
    "amounts.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6355194.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max\n",
    "amounts.reduce(lambda x, y: x if x > y else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min\n",
    "amounts.reduce(lambda x, y: x if x < y else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[15] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save this point into cache\n",
    "amounts.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232662, 184831898.49994844, 122763999131054.75)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate std by using formula\n",
    "count, total, sum_squares = amounts\\\n",
    "    .map(lambda amount: (1, amount, amount ** 2))\\\n",
    "    .reduce(lambda t1, t2: (t1[0] + t2[0], t1[1] + t2[1], t1[2] + t2[2]))\n",
    "\n",
    "count, total, sum_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149.94532037164157, 9978.482086123315)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "avg = total / count\n",
    "var = (sum_squares - count * (avg) ** 2) / count\n",
    "\n",
    "avg, sqrt(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Get stats on ticket amount for all tickets with destination MAD\n",
    "\n",
    "You will need to extract ticket amounts with destination MAD, and then calculate:\n",
    "\n",
    "1. Total ticket amounts per origin\n",
    "2. Top 10 airlines by average amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79062005698500', 'MAA', 'AUH', '9W', 56.79),\n",
       " ('79062005698500', 'AUH', 'CDG', '9W', 84.34),\n",
       " ('79062005924069', 'CJB', 'MAA', '9W', 60.0),\n",
       " ('79065668570385', 'DEL', 'DXB', '9W', 160.63),\n",
       " ('79065668737021', 'AUH', 'IXE', '9W', 152.46)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupons.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79062005639642', 'BRU', 'MAD', 'UX', 21.02),\n",
       " ('79065668754871', 'BRU', 'MAD', 'SN', 27.66),\n",
       " ('79065668917696', 'CDG', 'MAD', 'AF', 46.97),\n",
       " ('79062006133090', 'CDG', 'MAD', 'AF', 3.38),\n",
       " ('79062006110497', 'CDG', 'MAD', 'AF', 26.02)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouping all MAD destinations\n",
    "mad_coupons = coupons.filter(lambda coupon: coupon[2] == 'MAD')\n",
    "mad_coupons.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BRU', 21.02), ('BRU', 27.66), ('CDG', 46.97), ('CDG', 3.38), ('CDG', 26.02)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert each row to tuple for the interested columns\n",
    "pair_rdd = mad_coupons.map(lambda coupon: (coupon[1], coupon[4]))\n",
    "pair_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CCS', 94528.68),\n",
       " ('GRU', 87192.63999999998),\n",
       " ('EZE', 81074.63999999997),\n",
       " ('BOG', 74644.45000000001),\n",
       " ('LHR', 69609.53000000003)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use reduce to group them by key\n",
    "from operator import add\n",
    "\n",
    "result = pair_rdd.reduceByKey(add)\n",
    "result.takeOrdered(5, key=lambda t: -t[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79062005639642', 'BRU', 'MAD', 'UX', 21.02),\n",
       " ('79065668754871', 'BRU', 'MAD', 'SN', 27.66),\n",
       " ('79065668917696', 'CDG', 'MAD', 'AF', 46.97),\n",
       " ('79062006133090', 'CDG', 'MAD', 'AF', 3.38),\n",
       " ('79062006110497', 'CDG', 'MAD', 'AF', 26.02)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mad_coupons.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UX', (21.02, 1)),\n",
       " ('SN', (27.66, 1)),\n",
       " ('AF', (46.97, 1)),\n",
       " ('AF', (3.38, 1)),\n",
       " ('AF', (26.02, 1))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting columns needed\n",
    "mad_filtered = mad_coupons.map(lambda coupon: (coupon[3], (coupon[4], 1)))\n",
    "mad_filtered.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48.68, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a combiner that will operate the tuples\n",
    "tuple_a = (21.02, 1)\n",
    "tuple_b = (27.66, 1)\n",
    "\n",
    "def combiner(tuple_a, tuple_b):\n",
    "    return (tuple_a[0] + tuple_b[0], tuple_a[1] + tuple_b[1])\n",
    "\n",
    "combiner(tuple_a, tuple_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SN', (3092.6099999999997, 61)),\n",
       " ('IB', (928396.8400000058, 7526)),\n",
       " ('KL', (18007.62999999999, 323)),\n",
       " ('AZ', (3715.28, 54)),\n",
       " ('', (0.0, 168))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_per_airline = mad_filtered.reduceByKey(combiner) #only applies combiner to values\n",
    "counts_per_airline.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V0', 5418.098666666667),\n",
       " ('AC', 740.6200000000001),\n",
       " ('KE', 688.5261538461539),\n",
       " ('SV', 553.1742553191489),\n",
       " ('OB', 535.5044444444444),\n",
       " ('AR', 513.5304761904762),\n",
       " ('AV', 450.19509554140177),\n",
       " ('AM', 440.73421052631585),\n",
       " ('C2', 397.87),\n",
       " ('LA', 379.9537078651686)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages = counts_per_airline.mapValues(lambda t: t[0] / t[1]) #mapValues ignores the key (first element)\n",
    "averages.takeOrdered(10, key=lambda t: -t[-1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
