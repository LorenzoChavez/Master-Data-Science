{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First steps in PySpark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with RDD and Pair RDD abstractions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def plural(string): \n",
    "    return string + 's'\n",
    "\n",
    "hats = [ random.choice(['panama', 'sombrero', 'fedora', 'top hat']) for _ in range(100) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:480"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_rdd = sc.parallelize(hats) \n",
    "my_first_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals = my_first_rdd.map(plural) \n",
    "hat_plurals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['panamas', 'panamas', 'fedoras', 'sombreros', 'sombreros']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.take(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Calculate, from the rdd generated from hats, how many hats we have whose name does **not** start with an 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals\\\n",
    "    .filter(lambda x: x[0] != 's')\\\n",
    "    .count()\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Levels can save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import StorageLevel\n",
    "\n",
    "# Some of the possible storage levels\n",
    "StorageLevel.DISK_ONLY\n",
    "StorageLevel.MEMORY_AND_DISK_2\n",
    "StorageLevel.MEMORY_ONLY_SER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.cache() # equivalent to: hat_plurals.persist(StorageLevel.MEMORY_ONLY_SER) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.map(lambda x: 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.unpersist()\n",
    "hat_plurals.persist(StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, False, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_plurals.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartitioned = sc.parallelize(range(20)).repartition(5)\n",
    "repartitioned.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 16, 17, 18, 19],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [],\n",
       " [],\n",
       " [10, 11, 12, 13, 14]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartitioned.glom().collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping strategies in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['panama', 'panama', 'fedora', 'sombrero', 'sombrero']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('panama', 1), ('panama', 1), ('fedora', 1), ('sombrero', 1), ('sombrero', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd = my_first_rdd.map(lambda word: (word, 1))\n",
    "pair_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fedora', 24), ('top hat', 20), ('panama', 27), ('sombrero', 29)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd.groupByKey().mapValues(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fedora', 24), ('top hat', 20), ('panama', 27), ('sombrero', 29)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_rdd.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fedora', 24), ('top hat', 20), ('panama', 27)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing all steps at once\n",
    "my_first_rdd\\\n",
    "    .filter(lambda hat: hat[0] != 's')\\\n",
    "    .map(lambda hat: (hat, 1))\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apply word count to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [Complete Works of William Shakespeare](http://www.gutenberg.org/ebooks/100) from [Project Gutenberg](http://www.gutenberg.org/wiki/Main_Page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-08 12:38:33--  http://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5852404 (5,6M) [text/plain]\n",
      "Saving to: ‘shakespeare.txt’\n",
      "\n",
      "shakespeare.txt     100%[===================>]   5,58M  1,61MB/s    in 4,0s    \n",
      "\n",
      "2018-09-08 12:38:38 (1,41 MB/s) - ‘shakespeare.txt’ saved [5852404/5852404]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -v http://www.gutenberg.org/files/100/100-0.txt -O shakespeare.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing capitalization and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'see at the end of this file  content note added in 2017 '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test_line = 'See at the end of this file: * CONTENT NOTE (added in 2017) *'\n",
    "\n",
    "def clean(line):\n",
    "    return re.sub('[^\\w ]', '', line).lower()\n",
    "    \n",
    "clean(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'project gutenbergs the complete works of william shakespeare by william',\n",
       " 'shakespeare',\n",
       " '',\n",
       " 'this ebook is for the use of anyone anywhere in the united states and',\n",
       " 'most other parts of the world at no cost and with almost no restrictions',\n",
       " 'whatsoever  you may copy it give it away or reuse it under the terms',\n",
       " 'of the project gutenberg license included with this ebook or online at',\n",
       " 'wwwgutenbergorg  if you are not located in the united states youll',\n",
       " 'have to check the laws of the country where you are located before using']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lines = sc.textFile('shakespeare.txt')\n",
    "clean_lines = clean_lines.map(clean)\n",
    "clean_lines.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenbergs',\n",
       " 'the',\n",
       " 'complete',\n",
       " 'works',\n",
       " 'of',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'by',\n",
       " 'william']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = clean_lines.flatMap(lambda line: line.split()) \n",
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words.filter(lambda word: word != '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the words and show the top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "\n",
    "counts = words\\\n",
    "    .map(lambda word: (word, 1))\\\n",
    "    .reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 30002),\n",
       " ('and', 28358),\n",
       " ('i', 21867),\n",
       " ('to', 20816),\n",
       " ('of', 18815),\n",
       " ('a', 15992),\n",
       " ('you', 14437),\n",
       " ('my', 13191),\n",
       " ('in', 12032),\n",
       " ('that', 11781)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.takeOrdered(10, lambda tup: -tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical - ETL with airline coupon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['79062005698500,1,MAA,AUH,9W,9W,56.79,USD,1,H,H,0526,150904,OK,IAF0',\n",
       " '79062005698500,2,AUH,CDG,9W,9W,84.34,USD,1,H,H,6120,150905,OK,IAF0',\n",
       " '79062005924069,1,CJB,MAA,9W,9W,60.0,USD,1,H,H,2768,150721,OK,IAA0',\n",
       " '79065668570385,1,DEL,DXB,9W,9W,160.63,USD,2,S,S,0546,150804,OK,INA0',\n",
       " '79065668737021,1,AUH,IXE,9W,9W,152.46,USD,1,V,V,0501,150803,OK,INA0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile('coupon150720.csv')\n",
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Take fields 0, 2, 3, 4, and 6 from each line of coupons\n",
    "2. Keep only the amount. Get average, max, min and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('79062005698500', 'MAA', 'AUH', '9W', 56.79)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_line = '79062005698500,1,MAA,AUH,9W,9W,56.79,USD,1,H,H,0526,150904,OK,IAF0'\n",
    "\n",
    "def coupon_from_line(line):\n",
    "    fields = line.split(',')\n",
    "    return fields[0], fields[2], fields[3], fields[4], float(fields[6])\n",
    "\n",
    "coupon_from_line(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79062005698500', 'MAA', 'AUH', '9W', 56.79),\n",
       " ('79062005698500', 'AUH', 'CDG', '9W', 84.34),\n",
       " ('79062005924069', 'CJB', 'MAA', '9W', 60.0),\n",
       " ('79065668570385', 'DEL', 'DXB', '9W', 160.63),\n",
       " ('79065668737021', 'AUH', 'IXE', '9W', 152.46)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupons = lines.map(coupon_from_line)\n",
    "coupons.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56.79, 84.34, 60.0, 160.63]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amounts = coupons.map(lambda coupon: coupon[4])\n",
    "amounts.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6355194.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max\n",
    "amounts.reduce(lambda x, y: x if x > y else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min\n",
    "amounts.reduce(lambda x, y: x if x < y else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[15] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save this point into cache\n",
    "amounts.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232662, 184831898.49994844, 122763999131054.75)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate std by using formula\n",
    "count, total, sum_squares = amounts\\\n",
    "    .map(lambda amount: (1, amount, amount ** 2))\\\n",
    "    .reduce(lambda t1, t2: (t1[0] + t2[0], t1[1] + t2[1], t1[2] + t2[2]))\n",
    "\n",
    "count, total, sum_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149.94532037164157, 9978.482086123315)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "avg = total / count\n",
    "var = (sum_squares - count * (avg) ** 2) / count\n",
    "\n",
    "avg, sqrt(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Get stats on ticket amount for all tickets with destination MAD\n",
    "\n",
    "You will need to extract ticket amounts with destination MAD, and then calculate:\n",
    "\n",
    "1. Total ticket amounts per origin\n",
    "2. Top 10 airlines by average amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79062005698500', 'MAA', 'AUH', '9W', 56.79),\n",
       " ('79062005698500', 'AUH', 'CDG', '9W', 84.34),\n",
       " ('79062005924069', 'CJB', 'MAA', '9W', 60.0),\n",
       " ('79065668570385', 'DEL', 'DXB', '9W', 160.63),\n",
       " ('79065668737021', 'AUH', 'IXE', '9W', 152.46)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupons.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79062005639642', 'BRU', 'MAD', 'UX', 21.02),\n",
       " ('79065668754871', 'BRU', 'MAD', 'SN', 27.66),\n",
       " ('79065668917696', 'CDG', 'MAD', 'AF', 46.97),\n",
       " ('79062006133090', 'CDG', 'MAD', 'AF', 3.38),\n",
       " ('79062006110497', 'CDG', 'MAD', 'AF', 26.02)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouping all MAD destinations\n",
    "mad_coupons = coupons.filter(lambda coupon: coupon[2] == 'MAD')\n",
    "mad_coupons.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BRU', 21.02), ('BRU', 27.66), ('CDG', 46.97), ('CDG', 3.38), ('CDG', 26.02)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert each row to tuple for the interested columns\n",
    "pair_rdd = mad_coupons.map(lambda coupon: (coupon[1], coupon[4]))\n",
    "pair_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CCS', 94528.68),\n",
       " ('GRU', 87192.63999999998),\n",
       " ('EZE', 81074.63999999997),\n",
       " ('BOG', 74644.45000000001),\n",
       " ('LHR', 69609.53000000003)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use reduce to group them by key\n",
    "from operator import add\n",
    "\n",
    "result = pair_rdd.reduceByKey(add)\n",
    "result.takeOrdered(5, key=lambda t: -t[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79062005639642', 'BRU', 'MAD', 'UX', 21.02),\n",
       " ('79065668754871', 'BRU', 'MAD', 'SN', 27.66),\n",
       " ('79065668917696', 'CDG', 'MAD', 'AF', 46.97),\n",
       " ('79062006133090', 'CDG', 'MAD', 'AF', 3.38),\n",
       " ('79062006110497', 'CDG', 'MAD', 'AF', 26.02)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mad_coupons.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UX', (21.02, 1)),\n",
       " ('SN', (27.66, 1)),\n",
       " ('AF', (46.97, 1)),\n",
       " ('AF', (3.38, 1)),\n",
       " ('AF', (26.02, 1))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting columns needed\n",
    "mad_filtered = mad_coupons.map(lambda coupon: (coupon[3], (coupon[4], 1)))\n",
    "mad_filtered.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48.68, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a combiner that will operate the tuples\n",
    "tuple_a = (21.02, 1)\n",
    "tuple_b = (27.66, 1)\n",
    "\n",
    "def combiner(tuple_a, tuple_b):\n",
    "    return (tuple_a[0] + tuple_b[0], tuple_a[1] + tuple_b[1])\n",
    "\n",
    "combiner(tuple_a, tuple_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SN', (3092.6099999999997, 61)),\n",
       " ('IB', (928396.8400000058, 7526)),\n",
       " ('KL', (18007.62999999999, 323)),\n",
       " ('AZ', (3715.28, 54)),\n",
       " ('', (0.0, 168))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_per_airline = mad_filtered.reduceByKey(combiner) #only applies combiner to values\n",
    "counts_per_airline.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V0', 5418.098666666667),\n",
       " ('AC', 740.6200000000001),\n",
       " ('KE', 688.5261538461539),\n",
       " ('SV', 553.1742553191489),\n",
       " ('OB', 535.5044444444444),\n",
       " ('AR', 513.5304761904762),\n",
       " ('AV', 450.19509554140177),\n",
       " ('AM', 440.73421052631585),\n",
       " ('C2', 397.87),\n",
       " ('LA', 379.9537078651686)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages = counts_per_airline.mapValues(lambda t: t[0] / t[1]) #mapValues ignores the key (first element)\n",
    "averages.takeOrdered(10, key=lambda t: -t[-1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
